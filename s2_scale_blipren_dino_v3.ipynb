{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX94w-U1GC0S",
        "outputId": "34ae7439-ea6a-4909-f24c-8efa2817243d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login --relogin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "34c49f5ebd5247e59f6ff9271914a63f",
            "788e2491115e4a48bf7d2cbf7cba9634",
            "20aeacdd52374bd19ecec84cd42b75e8",
            "f18eafa149c94764bcefd634833d72ac",
            "28bd71a4f3064173be19781ca2b9a8d2",
            "e2f0c7ed215c4318a035659efc7af1a9",
            "b7bbf372727c4df29cbf3b04ee25760b",
            "749e06e6520b496f9b1302e82d144a12",
            "f7b387c385634e6eac7f96d3c1a23cf2",
            "27176dcde2064e2998ffe5be699a76d6",
            "cd6cd5b0021f4d4e9a3b6722aca7f8a8",
            "5eb6e74cf331400e931070f27a24fe89",
            "516539467df04db5bc78aea55a70a434",
            "393827b3ae6c4e25a43648904d0252d4",
            "f970e6a67dec4025a65e8411482e1b71",
            "bd9695d34898464996c8db0a34a1b665",
            "83b1c45c531248df9223d07d632d02fd",
            "76cbb4edd58c412882090ed1a1016d73",
            "ef2dd5514bbb47939f833fbe503ea747",
            "13d4aa466e1140078177ff83a9e36f9a"
          ]
        },
        "id": "ciCRanhhHAzr",
        "outputId": "d3b67e27-17ce-498a-9cac-1365b2eea871"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34c49f5ebd5247e59f6ff9271914a63f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rvHBlj4mHExD",
        "outputId": "3f8ee871-a03e-4aed-b4d0-f80ec50c608b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "âœ… BFloat16 supported! Using bfloat16 for Vision Encoder.\n",
            "Loading LLM: meta-llama/Llama-3.2-1B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Vision: facebook/dinov3-vitl16-pretrain-lvd1689m\n",
            "Loading dataset structure...\n",
            "Scanning dataset (target 50000)...\n",
            "Found 50000 cached items. Queued 0 downloads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meren23\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251202_003158-3bff6gh1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/eren23/blip2-llama-livis-dinov3-s2/runs/3bff6gh1' target=\"_blank\">vague-pine-9</a></strong> to <a href='https://wandb.ai/eren23/blip2-llama-livis-dinov3-s2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/eren23/blip2-llama-livis-dinov3-s2' target=\"_blank\">https://wandb.ai/eren23/blip2-llama-livis-dinov3-s2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/eren23/blip2-llama-livis-dinov3-s2/runs/3bff6gh1' target=\"_blank\">https://wandb.ai/eren23/blip2-llama-livis-dinov3-s2/runs/3bff6gh1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Training starting...\n",
            "[0] loss=8.0751 avg=8.0751 lr=0.000000e+00\n",
            "[200] loss=7.1019 avg=7.6656 lr=3.000000e-07\n",
            "[400] loss=4.7358 avg=6.8057 lr=6.000000e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 4.1672\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[600] loss=3.8949 avg=5.9477 lr=9.000000e-07\n",
            "[800] loss=3.6198 avg=5.4038 lr=1.250000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 3.2479\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000] loss=3.3748 avg=5.0087 lr=1.550000e-06\n",
            "[1200] loss=3.0432 avg=4.7059 lr=1.850000e-06\n",
            "[1400] loss=3.1641 avg=4.4683 lr=2.150000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.9432\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1600] loss=2.8095 avg=4.2771 lr=2.500000e-06\n",
            "[1800] loss=2.8216 avg=4.1213 lr=2.800000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.7732\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2000] loss=2.6710 avg=3.9900 lr=3.100000e-06\n",
            "[2200] loss=2.7051 avg=3.8761 lr=3.400000e-06\n",
            "[2400] loss=2.6930 avg=3.7759 lr=3.750000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.6253\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2600] loss=2.6533 avg=3.6882 lr=4.050000e-06\n",
            "[2800] loss=2.5510 avg=3.6112 lr=4.350000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.5774\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3000] loss=2.5330 avg=3.5433 lr=4.650000e-06\n",
            "[3200] loss=2.6728 avg=3.4818 lr=5.000000e-06\n",
            "[3400] loss=2.6263 avg=3.4278 lr=5.300000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.5418\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3600] loss=2.5923 avg=3.3792 lr=5.600000e-06\n",
            "[3800] loss=2.4285 avg=3.3354 lr=5.900000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.5152\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4000] loss=2.5265 avg=3.2954 lr=6.250000e-06\n",
            "[4200] loss=2.5410 avg=3.2584 lr=6.550000e-06\n",
            "[4400] loss=2.4535 avg=3.2248 lr=6.850000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.4998\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4600] loss=2.4649 avg=3.1935 lr=7.150000e-06\n",
            "[4800] loss=2.5993 avg=3.1649 lr=7.500000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.4831\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5000] loss=2.4529 avg=3.1379 lr=7.800000e-06\n",
            "[5200] loss=2.5097 avg=3.1124 lr=8.100000e-06\n",
            "[5400] loss=2.4026 avg=3.0885 lr=8.400000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.4621\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5600] loss=2.4013 avg=3.0665 lr=8.750000e-06\n",
            "[5800] loss=2.5826 avg=3.0455 lr=9.050000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.4559\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6000] loss=2.3844 avg=3.0255 lr=9.350000e-06\n",
            "[6200] loss=2.4717 avg=3.0071 lr=9.650000e-06\n",
            "[6400] loss=2.4776 avg=2.9897 lr=1.000000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.4261\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6600] loss=2.4522 avg=2.9729 lr=1.030000e-05\n",
            "[6800] loss=2.4737 avg=2.9568 lr=1.060000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.4266\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7000] loss=2.4795 avg=2.9419 lr=1.090000e-05\n",
            "[7200] loss=2.3441 avg=2.9277 lr=1.125000e-05\n",
            "[7400] loss=2.4335 avg=2.9139 lr=1.155000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.4073\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7600] loss=2.2451 avg=2.9009 lr=1.185000e-05\n",
            "[7800] loss=2.4178 avg=2.8884 lr=1.215000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3958\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8000] loss=2.4060 avg=2.8765 lr=1.250000e-05\n",
            "[8200] loss=2.5541 avg=2.8648 lr=1.280000e-05\n",
            "[8400] loss=2.3792 avg=2.8540 lr=1.310000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3915\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8600] loss=2.4438 avg=2.8433 lr=1.340000e-05\n",
            "[8800] loss=2.4622 avg=2.8329 lr=1.375000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3796\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9000] loss=2.2534 avg=2.8227 lr=1.405000e-05\n",
            "[9200] loss=2.3050 avg=2.8128 lr=1.435000e-05\n",
            "[9400] loss=2.4201 avg=2.8035 lr=1.465000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3759\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9600] loss=2.4055 avg=2.7945 lr=1.500000e-05\n",
            "[9800] loss=2.3908 avg=2.7860 lr=1.530000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3714\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10000] loss=2.5533 avg=2.7776 lr=1.560000e-05\n",
            "[10200] loss=2.3994 avg=2.7694 lr=1.590000e-05\n",
            "[10400] loss=2.4234 avg=2.7616 lr=1.625000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3398\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10600] loss=2.2754 avg=2.7540 lr=1.655000e-05\n",
            "[10800] loss=2.2902 avg=2.7464 lr=1.685000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3241\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11000] loss=2.3325 avg=2.7391 lr=1.715000e-05\n",
            "[11200] loss=2.2150 avg=2.7317 lr=1.750000e-05\n",
            "[11400] loss=2.3743 avg=2.7245 lr=1.780000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3388\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11600] loss=2.4096 avg=2.7177 lr=1.810000e-05\n",
            "[11800] loss=2.1906 avg=2.7111 lr=1.840000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3194\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12000] loss=2.3186 avg=2.7046 lr=1.875000e-05\n",
            "[12200] loss=2.4534 avg=2.6984 lr=1.905000e-05\n",
            "[12400] loss=2.3371 avg=2.6922 lr=1.935000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3014\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12600] loss=2.3572 avg=2.6862 lr=1.965000e-05\n",
            "[12800] loss=2.2148 avg=2.6801 lr=2.000000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3106\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13000] loss=2.3668 avg=2.6746 lr=2.030000e-05\n",
            "[13200] loss=2.2995 avg=2.6690 lr=2.060000e-05\n",
            "[13400] loss=2.2964 avg=2.6635 lr=2.090000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.3036\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13600] loss=2.3118 avg=2.6582 lr=2.125000e-05\n",
            "[13800] loss=2.3256 avg=2.6528 lr=2.155000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2914\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14000] loss=2.2421 avg=2.6475 lr=2.185000e-05\n",
            "[14200] loss=2.3293 avg=2.6425 lr=2.215000e-05\n",
            "[14400] loss=2.2898 avg=2.6374 lr=2.250000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2781\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14600] loss=2.1987 avg=2.6325 lr=2.280000e-05\n",
            "[14800] loss=2.2997 avg=2.6275 lr=2.310000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2789\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15000] loss=2.2487 avg=2.6228 lr=2.340000e-05\n",
            "[15200] loss=2.3594 avg=2.6183 lr=2.375000e-05\n",
            "[15400] loss=2.2571 avg=2.6140 lr=2.405000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2622\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15600] loss=2.3775 avg=2.6095 lr=2.435000e-05\n",
            "[15800] loss=2.2846 avg=2.6050 lr=2.465000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2622\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16000] loss=2.3150 avg=2.6007 lr=2.500000e-05\n",
            "[16200] loss=2.2814 avg=2.5965 lr=2.530000e-05\n",
            "[16400] loss=2.2716 avg=2.5923 lr=2.560000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2579\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16600] loss=2.2683 avg=2.5883 lr=2.590000e-05\n",
            "[16800] loss=2.2526 avg=2.5841 lr=2.625000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2439\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17000] loss=2.3444 avg=2.5802 lr=2.655000e-05\n",
            "[17200] loss=2.2392 avg=2.5764 lr=2.685000e-05\n",
            "[17400] loss=2.3293 avg=2.5726 lr=2.715000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2388\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17600] loss=2.2310 avg=2.5687 lr=2.750000e-05\n",
            "[17800] loss=2.4416 avg=2.5648 lr=2.780000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2301\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18000] loss=2.1236 avg=2.5611 lr=2.810000e-05\n",
            "[18200] loss=2.2221 avg=2.5574 lr=2.840000e-05\n",
            "[18400] loss=2.2049 avg=2.5537 lr=2.875000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2233\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18600] loss=2.2083 avg=2.5503 lr=2.905000e-05\n",
            "[18800] loss=2.3433 avg=2.5468 lr=2.935000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2284\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19000] loss=2.3070 avg=2.5433 lr=2.965000e-05\n",
            "[19200] loss=2.3099 avg=2.5400 lr=3.000000e-05\n",
            "[19400] loss=2.0875 avg=2.5366 lr=3.030000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2125\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19600] loss=2.3352 avg=2.5331 lr=3.060000e-05\n",
            "[19800] loss=2.0587 avg=2.5298 lr=3.090000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2118\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20000] loss=2.2703 avg=2.5265 lr=3.125000e-05\n",
            "[20200] loss=2.0928 avg=2.5233 lr=3.155000e-05\n",
            "[20400] loss=2.0919 avg=2.5203 lr=3.185000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.2037\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20600] loss=2.0998 avg=2.5172 lr=3.215000e-05\n",
            "[20800] loss=2.0946 avg=2.5140 lr=3.250000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.1932\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21000] loss=2.1824 avg=2.5110 lr=3.280000e-05\n",
            "[21200] loss=2.3118 avg=2.5080 lr=3.310000e-05\n",
            "[21400] loss=2.0775 avg=2.5050 lr=3.340000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.1939\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21600] loss=2.0568 avg=2.5021 lr=3.375000e-05\n",
            "[21800] loss=2.1583 avg=2.4992 lr=3.405000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.1895\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22000] loss=2.2354 avg=2.4963 lr=3.435000e-05\n",
            "[22200] loss=2.2148 avg=2.4935 lr=3.465000e-05\n",
            "[22400] loss=2.1163 avg=2.4906 lr=3.500000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.1767\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22600] loss=2.1305 avg=2.4878 lr=3.530000e-05\n",
            "[22800] loss=2.1996 avg=2.4850 lr=3.560000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.1786\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23000] loss=2.1616 avg=2.4823 lr=3.590000e-05\n",
            "[23200] loss=2.1574 avg=2.4796 lr=3.625000e-05\n",
            "[23400] loss=2.1477 avg=2.4770 lr=3.655000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.1855\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23600] loss=2.0997 avg=2.4744 lr=3.685000e-05\n",
            "[23800] loss=2.1233 avg=2.4718 lr=3.715000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.1833\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24000] loss=2.2286 avg=2.4692 lr=3.750000e-05\n",
            "[24200] loss=2.2873 avg=2.4666 lr=3.780000e-05\n",
            "[24400] loss=2.1911 avg=2.4641 lr=3.810000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.1702\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24600] loss=2.1059 avg=2.4617 lr=3.840000e-05\n",
            "[24800] loss=2.0879 avg=2.4593 lr=3.875000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL Loss: 2.1689\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25000] loss=2.0957 avg=2.4568 lr=3.905000e-05\n",
            "[25200] loss=2.1102 avg=2.4544 lr=3.935000e-05\n"
          ]
        }
      ],
      "source": [
        "import os, math, random, io, requests, json, time, torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.backends.backend_agg as agg\n",
        "\n",
        "from datasets import load_dataset, Dataset, Image as HFImage\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoImageProcessor,\n",
        "    AutoModel,\n",
        ")\n",
        "from torch.amp import autocast, GradScaler\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "\n",
        "# CONFIGURATION\n",
        "\n",
        "\n",
        "LLM_NAME    = \"meta-llama/Llama-3.2-1B\"\n",
        "VISION_NAME = \"facebook/dinov3-vitl16-pretrain-lvd1689m\"\n",
        "\n",
        "cache_dir        = \"/content/livis_cache\"\n",
        "max_cached_items = 50_000\n",
        "train_size       = 46_500\n",
        "val_size         = 3_000\n",
        "\n",
        "# S2 Configuration\n",
        "# Batch Size 4 -> Effectively 20 images per step (1 global + 4 crops per image).\n",
        "# If you have >40GB VRAM, you can try 6 or 8.\n",
        "batch_size    = 24\n",
        "s2_img_size   = 448    # High-res input\n",
        "base_img_size = 224    # Native DINO resolution\n",
        "\n",
        "max_txt_len  = 128\n",
        "total_steps  = 50000\n",
        "warmup_steps = 1000\n",
        "grad_accum   = 32     # High accumulation to stabilize the small batch size\n",
        "val_interval = 500    # Validate every 500 steps\n",
        "save_step_10k = 10000\n",
        "\n",
        "use_wandb   = True\n",
        "wandb_project = \"blip2-llama-livis-dinov3-s2\"\n",
        "wandb_val_samples = 4\n",
        "\n",
        "RESUME = False\n",
        "RESUME_QFORMER_PATH   = \"checkpoints/qformer_best.pt\"\n",
        "RESUME_PROJECTOR_PATH = \"checkpoints/projector_best.pt\"\n",
        "\n",
        "device = \"cuda\"\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "print(\"Device:\", device)\n",
        "\n",
        "if torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
        "    print(\"âœ… BFloat16 supported! Using bfloat16 for Vision Encoder.\")\n",
        "    vision_dtype = torch.bfloat16\n",
        "else:\n",
        "    print(\"âš ï¸ BFloat16 NOT supported. Using float32 for Vision Encoder.\")\n",
        "    vision_dtype = torch.float32\n",
        "\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "# MODEL LOADING\n",
        "\n",
        "\n",
        "print(f\"Loading LLM: {LLM_NAME}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLM_NAME)\n",
        "if tokenizer.pad_token is None: tokenizer.pad_token = tokenizer.eos_token\n",
        "llm = AutoModelForCausalLM.from_pretrained(LLM_NAME, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "llm.eval()\n",
        "d_model = llm.config.hidden_size\n",
        "\n",
        "print(f\"Loading Vision: {VISION_NAME}\")\n",
        "vision_model = AutoModel.from_pretrained(VISION_NAME, torch_dtype=vision_dtype, trust_remote_code=True).to(device)\n",
        "vision_processor = AutoImageProcessor.from_pretrained(VISION_NAME, trust_remote_code=True)\n",
        "vision_model.eval()\n",
        "\n",
        "# Force processor to use our High-Res S2 size\n",
        "if hasattr(vision_processor, \"size\"):\n",
        "    vision_processor.size = {\"height\": s2_img_size, \"width\": s2_img_size}\n",
        "if hasattr(vision_processor, \"crop_size\"):\n",
        "    vision_processor.crop_size = {\"height\": s2_img_size, \"width\": s2_img_size}\n",
        "\n",
        "d_vision = vision_model.config.hidden_size\n",
        "patch_sz = getattr(vision_model.config, \"patch_size\", 16)\n",
        "grid_sz  = base_img_size // patch_sz # Usually 224//16 = 14\n",
        "\n",
        "\n",
        "# S2-WRAPPER IMPLEMENTATION\n",
        "\n",
        "\n",
        "class S2VisionModule(nn.Module):\n",
        "    \"\"\"\n",
        "    S2-Wrapper: Scale on Scales.\n",
        "    Processes a high-res image (448) by:\n",
        "    1. Resizing to base (224) for Global view.\n",
        "    2. Splitting into 4x 224 crops for Local views.\n",
        "    3. Concatenating tokens -> 1 Global + 4 Local sets.\n",
        "    \"\"\"\n",
        "    def __init__(self, vision_model, base_size=224):\n",
        "        super().__init__()\n",
        "        self.vision_model = vision_model\n",
        "        self.base_size = base_size\n",
        "        self.dtype = vision_model.dtype\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        B, C, H, W = pixel_values.shape\n",
        "\n",
        "        # 1. Global Scale\n",
        "        global_view = F.interpolate(pixel_values, size=(self.base_size, self.base_size), mode='bilinear', align_corners=False)\n",
        "\n",
        "        # 2. Local Scale (Unfold)\n",
        "        kernel_size = self.base_size\n",
        "        stride = self.base_size\n",
        "        patches = pixel_values.unfold(2, kernel_size, stride).unfold(3, kernel_size, stride)\n",
        "        p_h = patches.size(2)\n",
        "        p_w = patches.size(3)\n",
        "\n",
        "        # Reshape to (B * num_crops, C, H_crop, W_crop)\n",
        "        local_views = patches.permute(0, 2, 3, 1, 4, 5).contiguous().reshape(-1, C, kernel_size, kernel_size)\n",
        "\n",
        "        # 3. Forward Passes (Batching Global + Local)\n",
        "        all_imgs = torch.cat([global_view, local_views], dim=0)\n",
        "        outputs = self.vision_model(pixel_values=all_imgs.to(self.dtype))\n",
        "        last_hidden = outputs.last_hidden_state\n",
        "\n",
        "        # Remove CLS token (index 0)\n",
        "        # We keep everything else (including registers) because we handle them later\n",
        "        spatial_tokens = last_hidden[:, 1:, :]\n",
        "\n",
        "        # 4. Reconstruct structure\n",
        "        global_tokens = spatial_tokens[:B] # (B, N, D)\n",
        "\n",
        "        local_tokens = spatial_tokens[B:]\n",
        "        local_tokens = local_tokens.reshape(B, p_h * p_w, -1, d_vision)\n",
        "        local_tokens_flat = local_tokens.reshape(B, -1, d_vision)\n",
        "\n",
        "        # 5. Concatenate Global + Local\n",
        "        # Order: [Global, TopLeft, TopRight, BotLeft, BotRight] (assuming 2x2 grid)\n",
        "        combined_tokens = torch.cat([global_tokens, local_tokens_flat], dim=1)\n",
        "\n",
        "        return combined_tokens\n",
        "\n",
        "s2_vision = S2VisionModule(vision_model, base_size=base_img_size)\n",
        "\n",
        "\n",
        "# DATASET\n",
        "\n",
        "\n",
        "print(\"Loading dataset structure...\")\n",
        "raw = load_dataset(\"laion/220k-GPT4Vision-captions-from-LIVIS\", split=\"train\")\n",
        "\n",
        "paths_ok = []\n",
        "caps_ok  = []\n",
        "jobs     = []\n",
        "needed   = max_cached_items\n",
        "\n",
        "print(f\"Scanning dataset (target {needed})...\")\n",
        "for idx, ex in enumerate(raw):\n",
        "    if len(paths_ok) + len(jobs) >= needed: break\n",
        "    url = ex.get(\"url\")\n",
        "    if not url: continue\n",
        "    img_path = os.path.join(cache_dir, f\"{idx:06d}.jpg\")\n",
        "    txt_path = os.path.join(cache_dir, f\"{idx:06d}.txt\")\n",
        "\n",
        "    sc = (ex.get(\"short_caption\") or \"\").strip()\n",
        "    if not sc: sc = (ex.get(\"caption\") or \"An image.\").strip()\n",
        "    cap = f\"Short caption: {sc}\"\n",
        "\n",
        "    if os.path.exists(img_path) and os.path.getsize(img_path) > 100:\n",
        "        paths_ok.append(img_path)\n",
        "        caps_ok.append(cap)\n",
        "        if not os.path.exists(txt_path):\n",
        "            with open(txt_path, \"w\", encoding=\"utf-8\") as f: f.write(cap)\n",
        "    else:\n",
        "        jobs.append((idx, url, cap))\n",
        "\n",
        "print(f\"Found {len(paths_ok)} cached items. Queued {len(jobs)} downloads.\")\n",
        "\n",
        "def fetch_one(job):\n",
        "    idx, url, cap = job\n",
        "    img_path = os.path.join(cache_dir, f\"{idx:06d}.jpg\")\n",
        "    txt_path = os.path.join(cache_dir, f\"{idx:06d}.txt\")\n",
        "    try:\n",
        "        r = requests.get(url, timeout=5)\n",
        "        img = Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
        "        img.save(img_path, \"JPEG\", quality=90)\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as f: f.write(cap)\n",
        "        return (img_path, cap)\n",
        "    except: return None\n",
        "\n",
        "if jobs:\n",
        "    print(f\"ðŸš€ Downloading {len(jobs)} images...\")\n",
        "    with ThreadPoolExecutor(max_workers=40) as ex_pool:\n",
        "        futures = {ex_pool.submit(fetch_one, j): j for j in jobs}\n",
        "        for i, fut in enumerate(as_completed(futures)):\n",
        "            res = fut.result()\n",
        "            if res:\n",
        "                p, c = res\n",
        "                paths_ok.append(p)\n",
        "                caps_ok.append(c)\n",
        "            if i % 1000 == 0 and i > 0: print(f\"Progress: {i}/{len(jobs)}...\")\n",
        "\n",
        "if len(paths_ok) < (train_size + val_size):\n",
        "    print(\"âš ï¸ Resizing splits.\")\n",
        "    val_size = min(val_size, int(len(paths_ok) * 0.1))\n",
        "    train_size = len(paths_ok) - val_size\n",
        "\n",
        "hf_ds = Dataset.from_dict({\"image\": paths_ok, \"caption\": caps_ok}).cast_column(\"image\", HFImage()).shuffle(seed=42)\n",
        "train_ds = hf_ds.select(range(train_size))\n",
        "val_ds   = hf_ds.select(range(train_size, train_size + val_size))\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, caps = [], []\n",
        "    for ex in batch:\n",
        "        img = ex[\"image\"]\n",
        "        if not isinstance(img, Image.Image):\n",
        "            try: img = img.convert(\"RGB\")\n",
        "            except: continue\n",
        "        else: img = img.convert(\"RGB\")\n",
        "        images.append(img)\n",
        "        caps.append(ex[\"caption\"])\n",
        "    if not images: return None\n",
        "    pixel_values = vision_processor(images=images, return_tensors=\"pt\")[\"pixel_values\"]\n",
        "    enc = tokenizer(caps, padding=\"max_length\", truncation=True, max_length=max_txt_len, return_tensors=\"pt\")\n",
        "    return {\"pixel_values\": pixel_values, \"input_ids\": enc[\"input_ids\"], \"attention_mask\": enc[\"attention_mask\"], \"captions\": caps}\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "# ARCHITECTURE (With View Embeddings)\n",
        "\n",
        "\n",
        "class QFormerBlock(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, mlp_ratio=4.0, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, n_heads, batch_first=True, dropout=dropout)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "        self.cross_attn = nn.MultiheadAttention(d_model, n_heads, batch_first=True, dropout=dropout)\n",
        "        self.ln3 = nn.LayerNorm(d_model)\n",
        "        hidden = int(d_model * mlp_ratio)\n",
        "        self.mlp = nn.Sequential(nn.Linear(d_model, hidden), nn.GELU(), nn.Linear(hidden, d_model), nn.Dropout(dropout))\n",
        "\n",
        "    def forward(self, q, v):\n",
        "        q2, _ = self.self_attn(self.ln1(q), self.ln1(q), self.ln1(q), need_weights=False)\n",
        "        q = q + q2\n",
        "        q2, attn = self.cross_attn(self.ln2(q), self.ln2(v), self.ln2(v), need_weights=True, average_attn_weights=False)\n",
        "        q = q + q2\n",
        "        q = q + self.mlp(self.ln3(q))\n",
        "        return q, attn\n",
        "\n",
        "class QFormer(nn.Module):\n",
        "    def __init__(self, d_vis, d_model, n_queries=32, n_layers=8, heads=8):\n",
        "        super().__init__()\n",
        "        self.query = nn.Parameter(torch.randn(n_queries, d_model))\n",
        "        self.vis_proj = nn.Linear(d_vis, d_model)\n",
        "\n",
        "        # --- NEW: View Embeddings for S2 ---\n",
        "        # 5 views: [Global, TL, TR, BL, BR]\n",
        "        # This helps the model distinguish spatial relationships between crops\n",
        "        self.view_emb = nn.Parameter(torch.randn(5, 1, d_model))\n",
        "        # -----------------------------------\n",
        "\n",
        "        self.layers = nn.ModuleList([QFormerBlock(d_model, heads) for _ in range(n_layers)])\n",
        "        self.final_ln = nn.LayerNorm(d_model)\n",
        "        self.last_attn = None\n",
        "\n",
        "    def forward(self, vis_tokens):\n",
        "        # vis_tokens: (B, Total_Tokens, D_vis)\n",
        "        v = self.vis_proj(vis_tokens)\n",
        "        B, N, D = v.shape\n",
        "\n",
        "        # Add View Embeddings\n",
        "        num_views = 5\n",
        "        if N % num_views == 0:\n",
        "            tokens_per_view = N // num_views\n",
        "            v = v.view(B, num_views, tokens_per_view, D)\n",
        "            # Broadcast (5, 1, D) -> (B, 5, T, D)\n",
        "            v = v + self.view_emb.unsqueeze(0)\n",
        "            v = v.reshape(B, N, D)\n",
        "\n",
        "        q = self.query.unsqueeze(0).expand(B, -1, -1)\n",
        "        for blk in self.layers:\n",
        "            q, attn = blk(q, v)\n",
        "            self.last_attn = attn\n",
        "        return self.final_ln(q)\n",
        "\n",
        "class Projector(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.mlp = nn.Sequential(nn.Linear(d_model, d_model*4), nn.GELU(), nn.Linear(d_model*4, d_model))\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "    def forward(self, x):\n",
        "        return self.ln2(x + self.mlp(self.ln1(x)))\n",
        "\n",
        "class BLIP2(nn.Module):\n",
        "    def __init__(self, llm, s2_vision, qformer, projector):\n",
        "        super().__init__()\n",
        "        self.llm, self.s2_vision, self.qformer, self.projector = llm, s2_vision, qformer, projector\n",
        "\n",
        "    def forward(self, input_ids, pixel_values, attention_mask):\n",
        "        with torch.no_grad():\n",
        "            with torch.amp.autocast(\"cuda\", enabled=False):\n",
        "                pv = pixel_values.to(self.s2_vision.dtype)\n",
        "                vtoks = self.s2_vision(pixel_values=pv)\n",
        "\n",
        "        q = self.qformer(vtoks.to(torch.float32))\n",
        "        q = self.projector(q).to(self.llm.dtype)\n",
        "\n",
        "        txt_emb = self.llm.get_input_embeddings()(input_ids)\n",
        "        all_emb = torch.cat([q, txt_emb], dim=1)\n",
        "        K = q.size(1)\n",
        "\n",
        "        prefix_mask = torch.ones((input_ids.size(0), K), device=device, dtype=attention_mask.dtype)\n",
        "        full_mask = torch.cat([prefix_mask, attention_mask], dim=1)\n",
        "\n",
        "        labels = input_ids.clone()\n",
        "        labels[attention_mask == 0] = -100\n",
        "        prefix_labels = torch.full((input_ids.size(0), K), -100, device=device, dtype=torch.long)\n",
        "        full_labels = torch.cat([prefix_labels, labels], dim=1)\n",
        "\n",
        "        return self.llm(inputs_embeds=all_emb, attention_mask=full_mask, labels=full_labels)\n",
        "\n",
        "qformer = QFormer(d_vision, d_model).to(device)\n",
        "projector = Projector(d_model).to(device)\n",
        "model = BLIP2(llm, s2_vision, qformer, projector)\n",
        "\n",
        "for p in llm.parameters(): p.requires_grad = False\n",
        "for p in vision_model.parameters(): p.requires_grad = False\n",
        "\n",
        "if RESUME:\n",
        "    try:\n",
        "        qformer.load_state_dict(torch.load(RESUME_QFORMER_PATH, map_location=device))\n",
        "        projector.load_state_dict(torch.load(RESUME_PROJECTOR_PATH, map_location=device))\n",
        "        print(\"âœ… Resumed from checkpoints.\")\n",
        "    except: print(\"âš ï¸ Resume failed, starting fresh.\")\n",
        "\n",
        "train_params = list(qformer.parameters()) + list(projector.parameters())\n",
        "optimizer = torch.optim.AdamW(train_params, lr=5e-5, weight_decay=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda s: s/warmup_steps if s<warmup_steps else max(0.1, 0.5*(1+math.cos(math.pi*(s-warmup_steps)/(total_steps-warmup_steps)))))\n",
        "scaler = GradScaler()\n",
        "\n",
        "if use_wandb:\n",
        "    import wandb\n",
        "    if wandb.run is None:\n",
        "        wandb.init(project=wandb_project, config={\"vision\": VISION_NAME, \"method\": \"S2-Wrapper-ViewEmb\"})\n",
        "\n",
        "\n",
        "\n",
        "# VISUALIZATION (Corrected)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_caption(img: Image.Image):\n",
        "    img = img.convert(\"RGB\")\n",
        "    pv = vision_processor(images=img, return_tensors=\"pt\")[\"pixel_values\"].to(device).to(vision_dtype)\n",
        "    vtoks = s2_vision(pixel_values=pv)\n",
        "    q = qformer(vtoks.to(torch.float32))\n",
        "    q = projector(q).to(llm.dtype)\n",
        "\n",
        "    prompt = \"Short caption: \"\n",
        "    ids = tokenizer(prompt, return_tensors=\"pt\").to(device)[\"input_ids\"]\n",
        "    txt_emb = llm.get_input_embeddings()(ids)\n",
        "    all_emb = torch.cat([q, txt_emb], dim=1)\n",
        "\n",
        "    out = llm.generate(inputs_embeds=all_emb, max_new_tokens=32, do_sample=False)\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True).replace(prompt, \"\").strip()\n",
        "\n",
        "def get_heatmap_image(img, display_count=8):\n",
        "    \"\"\"\n",
        "    Robust heatmap generation for S2 + DINOv3 (handles registers automatically).\n",
        "    \"\"\"\n",
        "    img = img.convert(\"RGB\")\n",
        "    pv = vision_processor(images=img, return_tensors=\"pt\")[\"pixel_values\"].to(device).to(vision_dtype)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        vtoks = s2_vision(pixel_values=pv)\n",
        "        qformer(vtoks.to(torch.float32))\n",
        "        attn_all = qformer.last_attn # (Batch=1, Heads, Queries, Keys)\n",
        "\n",
        "        # 1. Average over heads\n",
        "        attn_avg = attn_all.mean(dim=1).squeeze(0) # (32, TotalTokens)\n",
        "\n",
        "        # 2. Logic to extract the Spatial Grid from Global View\n",
        "        total_tokens = attn_avg.size(1)\n",
        "        num_views = 5\n",
        "        tokens_per_view = total_tokens // num_views # e.g. 200\n",
        "\n",
        "        expected_patches = grid_sz * grid_sz # e.g. 196\n",
        "        num_registers = tokens_per_view - expected_patches # e.g. 4\n",
        "\n",
        "        # We only look at Global View (first chunk), avoiding registers\n",
        "        # attn_global_patches: (32, 196)\n",
        "        attn_global_patches = attn_avg[:, num_registers : tokens_per_view]\n",
        "\n",
        "\n",
        "    # Plotting\n",
        "\n",
        "    display_count = min(display_count, 32)\n",
        "    total_cols = display_count + 1\n",
        "    fig, axes = plt.subplots(1, total_cols, figsize=(3 * total_cols, 3))\n",
        "\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title(\"Input\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    img_np = np.array(img)\n",
        "\n",
        "    for i in range(display_count):\n",
        "        ax = axes[i+1]\n",
        "\n",
        "        # Grab specific query attention\n",
        "        heat = attn_global_patches[i].view(grid_sz, grid_sz).float().cpu().numpy()\n",
        "        heat = (heat - heat.min()) / (heat.max() - heat.min() + 1e-8)\n",
        "\n",
        "        heat_img = Image.fromarray((heat * 255).astype(np.uint8)).resize(img.size, resample=Image.BILINEAR)\n",
        "\n",
        "        ax.imshow(img_np)\n",
        "        ax.imshow(heat_img, cmap=\"jet\", alpha=0.55)\n",
        "        ax.set_title(f\"Q{i}\")\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    canvas = agg.FigureCanvasAgg(fig)\n",
        "    canvas.draw()\n",
        "    rgba = np.asarray(canvas.buffer_rgba())\n",
        "    pil_img = Image.fromarray(rgba)\n",
        "    plt.close(fig)\n",
        "\n",
        "    return pil_img.convert(\"RGB\")\n",
        "\n",
        "\n",
        "# TRAINING LOOP\n",
        "\n",
        "print(\"ðŸš€ Training starting...\")\n",
        "best_val_loss = float(\"inf\")\n",
        "global_step = 0\n",
        "train_iter = iter(train_loader)\n",
        "running_loss = 0.0\n",
        "\n",
        "while global_step < total_steps:\n",
        "    try: batch = next(train_iter)\n",
        "    except:\n",
        "        train_iter = iter(train_loader)\n",
        "        batch = next(train_iter)\n",
        "    if not batch: continue\n",
        "\n",
        "    pixel_values = batch[\"pixel_values\"].to(device)\n",
        "    input_ids    = batch[\"input_ids\"].to(device)\n",
        "    attn_mask    = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "    with autocast(\"cuda\", dtype=torch.float16):\n",
        "        out = model(input_ids, pixel_values, attn_mask)\n",
        "        loss = out.loss / grad_accum\n",
        "\n",
        "    scaler.scale(loss).backward()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    if (global_step + 1) % grad_accum == 0:\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(train_params, 1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    if global_step % 200 == 0:\n",
        "        avg = running_loss / max(1, global_step+1)\n",
        "        lr = scheduler.get_last_lr()[0]\n",
        "        print(f\"[{global_step}] loss={loss.item()*grad_accum:.4f} avg={avg*grad_accum:.4f} lr={lr:.6e}\")\n",
        "        if use_wandb: wandb.log({\"train_loss\": loss.item()*grad_accum, \"lr\": lr}, step=global_step)\n",
        "\n",
        "    if (global_step + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        v_loss = 0\n",
        "        count = 0\n",
        "        with torch.no_grad():\n",
        "            for vb in val_loader:\n",
        "                if not vb: continue\n",
        "                with autocast(\"cuda\", dtype=torch.float16):\n",
        "                    out = model(vb[\"input_ids\"].to(device), vb[\"pixel_values\"].to(device), vb[\"attention_mask\"].to(device))\n",
        "                v_loss += out.loss.item()\n",
        "                count += 1\n",
        "                if count >= 100: break\n",
        "        v_loss /= max(1, count)\n",
        "        print(f\"VAL Loss: {v_loss:.4f}\")\n",
        "\n",
        "        if use_wandb:\n",
        "            wandb.log({\"val_loss\": v_loss}, step=global_step)\n",
        "            columns = [\"step\", \"image_vis\", \"gt\", \"pred\"]\n",
        "            val_table = wandb.Table(columns=columns)\n",
        "            indices = random.sample(range(len(val_ds)), min(len(val_ds), wandb_val_samples))\n",
        "            print(f\"Generating visualizations...\")\n",
        "            for idx in indices:\n",
        "                ex_img = val_ds[idx][\"image\"]\n",
        "                ex_gt  = val_ds[idx][\"caption\"]\n",
        "                ex_pred = generate_caption(ex_img)\n",
        "                vis_img = get_heatmap_image(ex_img)\n",
        "                val_table.add_data(global_step, wandb.Image(vis_img), ex_gt, ex_pred)\n",
        "            wandb.log({\"validation_samples\": val_table}, step=global_step)\n",
        "\n",
        "        if v_loss < best_val_loss:\n",
        "            best_val_loss = v_loss\n",
        "            torch.save(qformer.state_dict(), \"checkpoints/qformer_best.pt\")\n",
        "            torch.save(projector.state_dict(), \"checkpoints/projector_best.pt\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    global_step += 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34c49f5ebd5247e59f6ff9271914a63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_b7bbf372727c4df29cbf3b04ee25760b"
          }
        },
        "788e2491115e4a48bf7d2cbf7cba9634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_749e06e6520b496f9b1302e82d144a12",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f7b387c385634e6eac7f96d3c1a23cf2",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "20aeacdd52374bd19ecec84cd42b75e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_27176dcde2064e2998ffe5be699a76d6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cd6cd5b0021f4d4e9a3b6722aca7f8a8",
            "value": ""
          }
        },
        "f18eafa149c94764bcefd634833d72ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_5eb6e74cf331400e931070f27a24fe89",
            "style": "IPY_MODEL_516539467df04db5bc78aea55a70a434",
            "value": true
          }
        },
        "28bd71a4f3064173be19781ca2b9a8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_393827b3ae6c4e25a43648904d0252d4",
            "style": "IPY_MODEL_f970e6a67dec4025a65e8411482e1b71",
            "tooltip": ""
          }
        },
        "e2f0c7ed215c4318a035659efc7af1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd9695d34898464996c8db0a34a1b665",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_83b1c45c531248df9223d07d632d02fd",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "b7bbf372727c4df29cbf3b04ee25760b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "749e06e6520b496f9b1302e82d144a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b387c385634e6eac7f96d3c1a23cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27176dcde2064e2998ffe5be699a76d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6cd5b0021f4d4e9a3b6722aca7f8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5eb6e74cf331400e931070f27a24fe89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516539467df04db5bc78aea55a70a434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "393827b3ae6c4e25a43648904d0252d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f970e6a67dec4025a65e8411482e1b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "bd9695d34898464996c8db0a34a1b665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b1c45c531248df9223d07d632d02fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76cbb4edd58c412882090ed1a1016d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef2dd5514bbb47939f833fbe503ea747",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_13d4aa466e1140078177ff83a9e36f9a",
            "value": "Connecting..."
          }
        },
        "ef2dd5514bbb47939f833fbe503ea747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13d4aa466e1140078177ff83a9e36f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}